import streamlit as st
import pdfplumber
import pandas as pd
from io import BytesIO
import os
from dotenv import load_dotenv
import openai
import json
from datetime import datetime
import base64
import re
from PIL import Image

# å¯¼å…¥è‡ªå®šä¹‰å·¥å…·æ¨¡å—
try:
    from utils.pdf_processor import PDFProcessor
    from utils.ai_extractor import AIExtractor
    from utils.formatter import ResultFormatter
    from utils.report_generator import WordReportGenerator
    from utils.image_cropper import ImageCropper
    from utils.structured_extractor import StructuredExtractor
except ImportError as e:
    st.error(f"å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—å¤±è´¥: {str(e)}")
    st.stop()

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é¡µé¢è®¾ç½®ï¼šå®½å±æ¨¡å¼ï¼Œæ¨¡æ‹Ÿä»ªè¡¨ç›˜
st.set_page_config(
    layout="wide", 
    page_title="DeepSpec Pro",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .section-header {
        font-size: 1.5rem;
        color: #2ca02c;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }
    .highlight-green {
        background-color: #d4edda;
        padding: 10px;
        border-radius: 5px;
        border-left: 5px solid #28a745;
    }
    .highlight-yellow {
        background-color: #fff3cd;
        padding: 10px;
        border-radius: 5px;
        border-left: 5px solid #ffc107;
    }
    .highlight-red {
        background-color: #f8d7da;
        padding: 10px;
        border-radius: 5px;
        border-left: 5px solid #dc3545;
    }
    .parameter-table {
        width: 100%;
        border-collapse: collapse;
    }
    .parameter-table th, .parameter-table td {
        border: 1px solid #ddd;
        padding: 8px;
        text-align: left;
    }
    .parameter-table th {
        background-color: #f2f2f2;
    }
    .confidence-high {
        background-color: #d4edda;
    }
    .confidence-medium {
        background-color: #fff3cd;
    }
    .confidence-low {
        background-color: #f8d7da;
    }
    .equation-container {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
        font-family: 'Courier New', Courier, monospace;
    }
    .source-link {
        color: #1f77b4;
        text-decoration: none;
        font-weight: bold;
    }
    .source-link:hover {
        text-decoration: underline;
    }
    .paper-card {
        border: 1px solid #ddd;
        border-radius: 5px;
        padding: 10px;
        margin-bottom: 10px;
        background-color: white;
    }
    .selected-paper {
        border: 2px solid #1f77b4;
        box-shadow: 0 0 5px rgba(31, 119, 180, 0.3);
    }
</style>
""", unsafe_allow_html=True)

# åˆå§‹åŒ–Session State
def init_session_state():
    if 'pdf_processor' not in st.session_state:
        st.session_state.pdf_processor = PDFProcessor()
    if 'ai_extractor' not in st.session_state:
        st.session_state.ai_extractor = AIExtractor()
    if 'structured_extractor' not in st.session_state:
        st.session_state.structured_extractor = StructuredExtractor()
    if 'formatter' not in st.session_state:
        st.session_state.formatter = ResultFormatter()
    if 'extraction_result' not in st.session_state:
        st.session_state.extraction_result = None
    if 'structured_data' not in st.session_state:
        st.session_state.structured_data = None
    if 'uploaded_file' not in st.session_state:
        st.session_state.uploaded_file = None
    if 'comments' not in st.session_state:
        st.session_state.comments = {}
    if 'analyzed_papers' not in st.session_state:
        st.session_state.analyzed_papers = []
    if 'cropped_images' not in st.session_state:
        st.session_state.cropped_images = []

# åˆå§‹åŒ–Session State
init_session_state()

# ä¸»æ ‡é¢˜
st.markdown('<h1 class="main-header">DeepSpec Pro: SPE Paper Scrutinizer ğŸš€</h1>', unsafe_allow_html=True)
st.markdown("---")

# --- Sidebar: ä¸Šä¼ ä¸æ§åˆ¶ ---
with st.sidebar:
    st.header("1. æ–‡çŒ®å¯¼å…¥")
    uploaded_file = st.file_uploader("ä¸Šä¼  PDF (SPE Paper)", type="pdf")
    
    if uploaded_file is not None and uploaded_file != st.session_state.uploaded_file:
        st.session_state.uploaded_file = uploaded_file
        # é‡ç½®æå–ç»“æœ
        st.session_state.extraction_result = None
        st.session_state.structured_data = None
        st.session_state.comments = {}
        st.session_state.cropped_images = []
        # å¤„ç†PDF
        with st.spinner("æ­£åœ¨å¤„ç†PDFæ–‡ä»¶..."):
            st.session_state.pdf_processor.process_pdf(uploaded_file)
    
    st.header("2. ç§‘å­¦å®¶è®¾å®š")
    role = st.selectbox("å½“å‰è§’è‰²", ["æ°´åŠ›å‹è£‚ä¸“å®¶", "æ²¹è—æ•°å€¼æ¨¡æ‹Ÿä¸“å®¶", "æœºå™¨å­¦ä¹ ä¸“å®¶", "é€šç”¨ç ”ç©¶å‘˜"])
    
    api_key = st.text_input("OpenAI API Key", type="password")
    
    if api_key:
        os.environ["OPENAI_API_KEY"] = api_key
    
    st.header("3. åˆ†ææ¨¡å¼")
    extraction_mode = st.selectbox(
        "æå–æ¨¡å¼",
        ["å¿«é€Ÿæå–", "æ ‡å‡†æå–", "æ·±åº¦æå–"],
        index=1,
        help="ä¸åŒæ¨¡å¼ä¼šå½±å“åˆ†æçš„æ·±åº¦å’Œå‡†ç¡®æ€§"
    )
    
    st.header("4. æ“ä½œ")
    
    # åˆ†ææŒ‰é’®
    if st.button("ğŸ¤– AI åˆ†æ", disabled=(uploaded_file is None or not api_key)):
        with st.spinner("æ­£åœ¨åƒé¦–å¸­ç§‘å­¦å®¶ä¸€æ ·é˜…è¯»..."):
            try:
                # è·å–PDFæ–‡æœ¬ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»PDFå¤„ç†å™¨ä¸­è·å–ï¼‰
                pages_text = ""
                for i, page in enumerate(st.session_state.pdf_processor.pages[:5]):  # åªå¤„ç†å‰5é¡µ
                    page_text = page.extract_text()
                    if page_text:
                        pages_text += f"Page {i+1}:\n{page_text}\n\n"
                
                # ä½¿ç”¨ç»“æ„åŒ–æå–å™¨è·å–æ•°æ®
                if pages_text:
                    st.session_state.structured_data = st.session_state.structured_extractor.extract_structured_data(
                        pages_text, role, extraction_mode
                    )
                else:
                    # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                    st.session_state.structured_data = st.session_state.structured_extractor.get_mock_structured_data()
                
                st.success("âœ… åˆ†æå®Œæˆï¼")
            except Exception as e:
                st.error(f"åˆ†æå¤±è´¥: {str(e)}")
                # ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®ä½œä¸ºåå¤‡
                st.session_state.structured_data = st.session_state.structured_extractor.get_mock_structured_data()
                st.info("å·²ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œåˆ†æ")
    
    # å¯¼å‡ºæŒ‰é’®
    if st.session_state.analyzed_papers and st.button("ğŸ“¥ ç”Ÿæˆ Word æŠ¥å‘Š"):
        generate_word_report()

# --- ä¸»ç•Œé¢ ---
if st.session_state.uploaded_file:
    file_name = st.session_state.uploaded_file.name
    file_size = st.session_state.uploaded_file.size / (1024 * 1024)  # MB
    
    st.caption(f"æ–‡ä»¶: {file_name} | å¤§å°: {file_size:.2f} MB")
    
    if st.session_state.structured_data:
        data = st.session_state.structured_data
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            st.subheader("ğŸ“ ç¼–è¾‘å†…å®¹ (æ‰€è§å³æ‰€å¾—)")
            
            # å…è®¸ç”¨æˆ·ä¿®æ”¹AIçš„ç»“æœ
            title = st.text_input("è®ºæ–‡æ ‡é¢˜", value=data.get('title', ''))
            purpose = st.text_area("ç ”ç©¶ç›®çš„", value=data.get('purpose', ''), height=100)
            
            # ç¼–è¾‘ç»“è®º
            st.write("**æ ¸å¿ƒç»“è®º:**")
            conclusions = data.get('conclusion', [])
            if isinstance(conclusions, str):
                conclusions = [conclusions]
            
            edited_conclusions = []
            for i, conclusion in enumerate(conclusions):
                with st.expander(f"ç»“è®º {i+1}", expanded=True):
                    edited_conclusion = st.text_area(
                        f"ç»“è®º {i+1}",
                        value=conclusion,
                        key=f"conclusion_{i}"
                    )
                    edited_conclusions.append(edited_conclusion)
            
            # ç¼–è¾‘å‚æ•°
            params = st.text_area("è¯¦ç»†å‚æ•°", value=data.get('params', ''), height=100)
            
            # ç¼–è¾‘å…¬å¼
            st.write("**æ ¸å¿ƒå…¬å¼:**")
            formulas = data.get('formulas', [])
            if isinstance(formulas, str):
                formulas = [formulas]
            
            edited_formulas = []
            for i, formula in enumerate(formulas):
                with st.expander(f"å…¬å¼ {i+1}", expanded=False):
                    edited_formula = st.text_area(
                        f"å…¬å¼ {i+1}",
                        value=formula,
                        key=f"formula_{i}"
                    )
                    edited_formulas.append(edited_formula)
            
            # ç¼–è¾‘è¯„è®ºå’Œæ ‡ç­¾
            comments = st.text_area("Comments (æƒ³æ³•)", value=data.get('comments', ''))
            why = st.text_area("Why (æ ‡ç­¾)", value=data.get('why', ''))
            
            # å­˜å‚¨ç¼–è¾‘åçš„æ•°æ®
            edited_data = {
                'title': title,
                'purpose': purpose,
                'conclusion': edited_conclusions,
                'params': params,
                'formulas': edited_formulas,
                'comments': comments,
                'why': why,
                'page_source': data.get('page_source', '')
            }
            
            # æ·»åŠ åˆ°æŠ¥å‘ŠæŒ‰é’®
            if st.button("â• å°†æ­¤æ¡ç›®æ·»åŠ åˆ° Word æŠ¥å‘Š"):
                # è·å–é€‰ä¸­çš„å›¾ç‰‡
                selected_image = None
                if 'selected_image_index' in st.session_state and st.session_state.selected_image_index >= 0:
                    if st.session_state.selected_image_index < len(st.session_state.cropped_images):
                        selected_image = st.session_state.cropped_images[st.session_state.selected_image_index]
                
                # åˆ›å»ºæ¡ç›®
                entry = {
                    "title": title,
                    "purpose": purpose,
                    "conclusion": edited_conclusions,
                    "params": params,
                    "formulas": edited_formulas,
                    "comments": comments,
                    "why": why,
                    "page_source": data.get('page_source', ''),
                    "image": selected_image
                }
                
                # æ·»åŠ åˆ°å·²åˆ†æè®ºæ–‡åˆ—è¡¨
                st.session_state.analyzed_papers.append(entry)
                
                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                st.toast(f"âœ… å·²æ·»åŠ ï¼å½“å‰æŠ¥å‘Šå·²æœ‰ {len(st.session_state.analyzed_papers)} ç¯‡æ–‡çŒ®ã€‚")
                
                # æ¸…ç©ºé€‰ä¸­çš„å›¾ç‰‡
                if 'selected_image_index' in st.session_state:
                    st.session_state.selected_image_index = -1
        
        with col2:
            st.subheader("ğŸ“¸ æˆªå›¾è¯æ®")
            
            # æ˜¾ç¤ºPDFé¡µé¢å›¾ç‰‡é€‰æ‹©
            page_count = st.session_state.pdf_processor.get_page_count()
            
            if page_count > 0:
                selected_page = st.selectbox(
                    "é€‰æ‹©é¡µé¢",
                    options=list(range(1, page_count + 1)),
                    format_func=lambda x: f"ç¬¬ {x} é¡µ"
                )
                
                # è·å–é¡µé¢å›¾åƒ
                page_image = ImageCropper.extract_pdf_page_as_image(
                    st.session_state.pdf_processor, 
                    selected_page
                )
                
                if page_image:
                    st.image(page_image, caption=f"ç¬¬ {selected_page} é¡µ", use_column_width=True)
                    
                    # è£å‰ªå›¾ç‰‡
                    st.write("### å›¾ç‰‡è£å‰ª")
                    cropped_image = ImageCropper.crop_image_with_streamlit(page_image, f"page_{selected_page}")
                    
                    if cropped_image:
                        st.image(cropped_image, caption="è£å‰ªåçš„å›¾ç‰‡", use_column_width=True)
                        
                        if st.button(f"å°†æ­¤å›¾ç‰‡æ·»åŠ åˆ°æŠ¥å‘Š", key=f"add_cropped_{selected_page}"):
                            st.session_state.cropped_images.append(cropped_image)
                            st.toast(f"å·²æ·»åŠ è£å‰ªå›¾ç‰‡ï¼å½“å‰æœ‰ {len(st.session_state.cropped_images)} å¼ å›¾ç‰‡ã€‚")
            
            # æ˜¾ç¤ºå·²è£å‰ªçš„å›¾ç‰‡
            if st.session_state.cropped_images:
                st.write("### å·²è£å‰ªçš„å›¾ç‰‡")
                for i, img in enumerate(st.session_state.cropped_images):
                    col_img, col_btn = st.columns([3, 1])
                    
                    with col_img:
                        if st.image(img, caption=f"å›¾ç‰‡ {i+1}", use_column_width=True):
                            pass
                    
                    with col_btn:
                        if st.button(f"ä½¿ç”¨", key=f"use_img_{i}"):
                            st.session_state.selected_image_index = i
                            st.toast(f"å·²é€‰æ‹©å›¾ç‰‡ {i+1} ç”¨äºæ’å…¥åˆ°æŠ¥å‘Šä¸­")
                        
                        if st.button(f"åˆ é™¤", key=f"del_img_{i}"):
                            st.session_state.cropped_images.pop(i)
                            st.experimental_rerun()
    
    # PDFé¢„è§ˆåŒºåŸŸ
    st.markdown("---")
    st.subheader("ğŸ” PDF é¢„è§ˆ")
    
    if hasattr(st.session_state.pdf_processor, 'pages'):
        page_count = len(st.session_state.pdf_processor.pages)
        
        # é¡µé¢é€‰æ‹©å™¨
        target_page = st.session_state.get('target_page', 1)
        if target_page < 1 or target_page > page_count:
            target_page = 1
        
        selected_page = st.number_input(
            f"é€‰æ‹©é¡µé¢ (1-{page_count})",
            min_value=1,
            max_value=page_count,
            value=target_page
        )
        
        # æ˜¾ç¤ºé¡µé¢å†…å®¹
        if selected_page <= page_count:
            page = st.session_state.pdf_processor.pages[selected_page-1]
            
            # è·å–é¡µé¢æ–‡æœ¬
            try:
                page_text = page.extract_text()
                if not page_text:
                    page_text = "æ­¤é¡µæ— æ–‡æœ¬å†…å®¹"
            except Exception as e:
                page_text = f"æå–æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}"
            
            # æ˜¾ç¤ºæ–‡æœ¬
            st.text_area("é¡µé¢å†…å®¹:", value=page_text, height=300)
            
            # æ˜¾ç¤ºé¡µé¢å›¾åƒ
            full_page_image = st.session_state.pdf_processor.get_page_as_image(selected_page)
            if full_page_image:
                try:
                    st.image(f"data:image/png;base64,{full_page_image['base64']}", 
                            caption=f"é¡µé¢ {selected_page}")
                except Exception as e:
                    st.info(f"æ— æ³•æ˜¾ç¤ºå®Œæ•´é¡µé¢å›¾åƒ: {str(e)}")
else:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼  SPE è®ºæ–‡ PDF ä»¥å¼€å§‹ã€‚")

# --- åº•éƒ¨ï¼šå·²æ·»åŠ çš„è®ºæ–‡åˆ—è¡¨ ---
if st.session_state.analyzed_papers:
    st.markdown("---")
    st.subheader(f"ğŸ“‹ å·²æ·»åŠ çš„è®ºæ–‡ ({len(st.session_state.analyzed_papers)} ç¯‡)")
    
    for i, paper in enumerate(st.session_state.analyzed_papers):
        with st.expander(f"{i+1}. {paper['title']}", expanded=False):
            col1, col2, col3 = st.columns([3, 1, 1])
            
            with col1:
                st.write(f"**ç›®çš„**: {paper['purpose']}")
                st.write(f"**è¯„è®º**: {paper['comments']}")
            
            with col2:
                if paper['image']:
                    st.image(paper['image'], caption="å…³é”®å›¾è¡¨", width=150)
            
            with col3:
                if st.button(f"åˆ é™¤", key=f"del_paper_{i}"):
                    st.session_state.analyzed_papers.pop(i)
                    st.experimental_rerun()

# --- Wordæ–‡æ¡£ç”Ÿæˆå‡½æ•° ---
def generate_word_report():
    """ç”ŸæˆWordæ–‡æ¡£"""
    if not st.session_state.analyzed_papers:
        st.error("æ²¡æœ‰å¯å¯¼å‡ºçš„è®ºæ–‡")
        return
    
    with st.spinner("æ­£åœ¨ç”ŸæˆWordæ–‡æ¡£..."):
        try:
            # åˆ›å»ºWordæŠ¥å‘Šç”Ÿæˆå™¨
            report_gen = WordReportGenerator()
            
            # æ·»åŠ æ¯ç¯‡è®ºæ–‡çš„åˆ†æ
            for paper in st.session_state.analyzed_papers:
                image_stream = None
                if paper['image']:
                    # å°†PILå›¾åƒè½¬æ¢ä¸ºå­—èŠ‚æµ
                    img_buffer = BytesIO()
                    paper['image'].save(img_buffer, format='PNG')
                    img_buffer.seek(0)
                    image_stream = img_buffer
                
                report_gen.add_paper_analysis(paper, image_stream=image_stream)
            
            # ä¿å­˜åˆ°å­—èŠ‚æµ
            buffer = report_gen.save_to_bytes()
            
            # æä¾›ä¸‹è½½æŒ‰é’®
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Word æŠ¥å‘Š",
                data=buffer,
                file_name=f"SPE_Literature_Review_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
            
            st.success("âœ… Word æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
            
        except Exception as e:
            st.error(f"ç”ŸæˆWordæ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")

# --- åº•éƒ¨ä¿¡æ¯ ---
st.markdown("---")
st.markdown("Â© 2023 DeepSpec Pro: SPE Paper Scrutinizer - ä¸ºçŸ³æ²¹å·¥ç¨‹å¸ˆæ‰“é€ çš„ä¸“ä¸šæ–‡çŒ®åˆ†æå·¥å…·")