import streamlit as st
import pandas as pd
from io import BytesIO
import os
from dotenv import load_dotenv
from PIL import Image

# å¼•å…¥å·¥å…·æ¨¡å—
try:
    from utils.pdf_processor import PDFProcessor
    from utils.ai_extractor import AIExtractor
    from utils.structured_extractor import StructuredExtractor
    from utils.report_generator import WordReportGenerator
    from utils.image_cropper import ImageCropper
except ImportError:
    st.error("âŒ æ ¸å¿ƒæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œè¯·ç¡®ä¿ utils æ–‡ä»¶å¤¹åŠä¾èµ–åº“å®Œæ•´ã€‚")
    st.stop()

load_dotenv()

st.set_page_config(layout="wide", page_title="DeepSpec V3.1", initial_sidebar_state="expanded")

# --- å…¨å±€çŠ¶æ€åˆå§‹åŒ– ---
if 'papers_data' not in st.session_state:
    st.session_state.papers_data = {}
if 'current_file' not in st.session_state:
    st.session_state.current_file = None
if 'word_buffer' not in st.session_state:
    st.session_state.word_buffer = None  # ç”¨äºç¼“å­˜ç”Ÿæˆçš„ Word æ–‡ä»¶

# --- CSS æ ·å¼å¾®è°ƒ ---
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 5px;}
    /* è°ƒæ•´è¡¨æ ¼å­—ä½“ï¼Œä½¿å…¶æ›´åƒ Word é¢„è§ˆ */
    .dataframe {font-family: 'Arial', sans-serif; font-size: 12px;}
    div[data-testid="stExpander"] details summary {font-weight: bold; color: #1f77b4;}
</style>
""", unsafe_allow_html=True)

# ================= ä¾§è¾¹æ ï¼šå·¥ä½œæµæ§åˆ¶ =================
with st.sidebar:
    st.title("ğŸ“š DeepSpec å·¥ä½œå°")
    
    # 1. æ‰¹é‡ä¸Šä¼ 
    uploaded_files = st.file_uploader("1. æ‰¹é‡ä¸Šä¼  PDF", type="pdf", accept_multiple_files=True)
    if uploaded_files:
        for f in uploaded_files:
            if f.name not in st.session_state.papers_data:
                st.session_state.papers_data[f.name] = {
                    "file_obj": f,
                    "status": "å¾…åˆ†æ",  # å¾…åˆ†æ -> å·²æå– -> å·²å®¡æ ¸
                    "extracted_data": None,
                    "pdf_processor": PDFProcessor(),
                    "selected_image": None
                }
    
    st.divider()
    
    # 2. AI è®¾ç½®ä¸æå–
    role = st.selectbox("è®¾å®š AI è§’è‰²", ["æ°´åŠ›å‹è£‚ä¸“å®¶", "æ²¹è—æ•°å€¼æ¨¡æ‹Ÿä¸“å®¶", "æœºå™¨å­¦ä¹ ä¸“å®¶"])
    api_key = st.text_input("OpenAI API Key", type="password")
    if api_key: os.environ["OPENAI_API_KEY"] = api_key
    
    pending_files = [name for name, info in st.session_state.papers_data.items() if info['status'] == "å¾…åˆ†æ"]
    if pending_files:
        st.info(f"é˜Ÿåˆ—å¾…å¤„ç†: {len(pending_files)} ç¯‡")
        if st.button(f"ğŸš€ æ‰¹é‡ AI æå–", type="primary"):
            if not api_key:
                st.error("è¯·å…ˆé…ç½® API Key")
            else:
                progress_bar = st.progress(0)
                for idx, fname in enumerate(pending_files):
                    info = st.session_state.papers_data[fname]
                    # é¢„å¤„ç† PDF
                    info['pdf_processor'].process_pdf(info['file_obj'])
                    text = info['pdf_processor'].extract_text_by_page(1) + \
                           info['pdf_processor'].extract_text_by_page(2) + \
                           info['pdf_processor'].extract_text_by_page(3)
                    # AI æå–
                    try:
                        extractor = StructuredExtractor()
                        data = extractor.extract_structured_data(text, role=role)
                        info['extracted_data'] = data
                        info['status'] = "å·²æå–"
                    except Exception as e:
                        st.error(f"{fname} æå–å¤±è´¥: {e}")
                    progress_bar.progress((idx + 1) / len(pending_files))
                st.success("æå–å®Œæˆï¼è¯·åœ¨å³ä¾§é€ä¸€å®¡æ ¸ã€‚")
                st.rerun()  # ã€ä¿®å¤ç‚¹ã€‘ä» st.experimental_rerun() æ”¹ä¸º st.rerun()
    
    st.divider()

    # 3. è®ºæ–‡å¯¼èˆª
    st.subheader("ğŸ“‘ è®ºæ–‡åˆ—è¡¨")
    sorted_files = sorted(st.session_state.papers_data.items(), key=lambda x: x[1]['status'] == "å·²å®¡æ ¸", reverse=True)
    for fname, info in sorted_files:
        icon = "âœ…" if info['status'] == "å·²å®¡æ ¸" else ("ğŸ¤–" if info['status'] == "å·²æå–" else "â³")
        if st.button(f"{icon} {fname}", key=f"nav_{fname}"):
            st.session_state.current_file = fname

# ================= ä¸»å·¥ä½œåŒº =================

# åˆ›å»ºä¸¤ä¸ª Tabï¼šä¸€ä¸ªæ˜¯å•ç¯‡ç¼–è¾‘ï¼Œä¸€ä¸ªæ˜¯å…¨å±€é¢„è§ˆ
tab_edit, tab_preview = st.tabs(["âœï¸ å•ç¯‡ç²¾ä¿® (Editor)", "ğŸ‘€ æŠ¥å‘Šé¢„è§ˆ (Word Preview)"])

# --- Tab 1: å•ç¯‡ç²¾ä¿® ---
with tab_edit:
    if st.session_state.current_file:
        fname = st.session_state.current_file
        info = st.session_state.papers_data[fname]
        
        st.caption(f"å½“å‰æ­£åœ¨ç¼–è¾‘: {fname} | çŠ¶æ€: {info['status']}")
        
        if info['status'] == "å¾…åˆ†æ":
            st.warning("âš ï¸ æ­¤æ–‡ä»¶å°šæœªè¿›è¡Œ AI æå–ï¼Œè¯·å…ˆåœ¨å·¦ä¾§ç‚¹å‡»â€œæ‰¹é‡ AI æå–â€ã€‚")
        else:
            data = info['extracted_data']
            
            # åŒæ å¸ƒå±€ï¼šå·¦ç¼–è¾‘ï¼Œå³å›¾è¡¨
            col_form, col_media = st.columns([1.3, 1])
            
            with col_form:
                st.subheader("1. ç»“æ„åŒ–æ•°æ®æ ¡å¯¹")
                # ã€æ¢å¤ç‚¹ã€‘å› ä¸ºæ‚¨å·²å‡çº§åˆ°æ–°ç‰ˆ Streamlitï¼Œborder=True å¯ä»¥ä½¿ç”¨äº†
                with st.container(border=True):
                    new_title = st.text_input("è®ºæ–‡æ ‡é¢˜ (Article)", data.get('title', ''))
                    new_purpose = st.text_area("ç ”ç©¶ç›®çš„ (Purpose)", data.get('purpose', ''), height=80)
                    
                    # ç»“è®ºç¼–è¾‘
                    st.markdown("**æ ¸å¿ƒç»“è®º (Conclusions)**")
                    conclusions = data.get('conclusion', [])
                    if isinstance(conclusions, str): conclusions = [conclusions]
                    new_conclusions = []
                    for i, c in enumerate(conclusions):
                        new_c = st.text_area(f"ç»“è®º {i+1}", c, key=f"c_{fname}_{i}", height=60)
                        new_conclusions.append(new_c)
                    
                    new_params = st.text_area("å…³é”®å‚æ•° (Parameters)", data.get('params', ''), height=100)
                    
                    # å…¬å¼ç¼–è¾‘
                    st.markdown("**æ§åˆ¶æ–¹ç¨‹ (Formulas)**")
                    formulas = data.get('formulas', [])
                    if isinstance(formulas, str): formulas = [formulas]
                    new_formulas = []
                    for i, f in enumerate(formulas):
                        f_col1, f_col2 = st.columns([3, 1])
                        with f_col1:
                            new_f = st.text_input(f"LaTeX Code {i+1}", f, key=f"f_{fname}_{i}")
                        with f_col2:
                            try: st.latex(new_f)
                            except: st.caption("æ¸²æŸ“å¤±è´¥")
                        new_formulas.append(new_f)

                    new_comments = st.text_area("ä¸“å®¶æ‰¹æ³¨ (Comments)", data.get('comments', ''))
                    new_why = st.text_input("æ ‡ç­¾ (Why)", data.get('why', ''))

            with col_media:
                st.subheader("2. å›¾è¡¨è¯æ®é“¾ (Evidence)")
                if not info['pdf_processor'].pages:
                    info['pdf_processor'].process_pdf(info['file_obj'])
                
                total_pages = info['pdf_processor'].get_page_count()
                page_num = st.number_input("é€‰æ‹© PDF é¡µç ", 1, total_pages, 1, key=f"pg_{fname}")
                
                page_img = ImageCropper.extract_pdf_page_as_image(info['pdf_processor'], page_num)
                if page_img:
                    st.info("ğŸ‘‡ åœ¨ä¸‹æ–¹æ‹–æ‹½æ¡†é€‰å…³é”®å›¾è¡¨ï¼Œç„¶åç‚¹å‡»â€œæˆªå–â€")
                    cropped = ImageCropper.crop_image_with_streamlit(page_img, key_prefix=f"crop_{fname}")
                    
                    if st.button("ğŸ“¸ ç¡®è®¤æˆªå–å¹¶ä½¿ç”¨", key=f"btn_crop_{fname}"):
                        info['selected_image'] = cropped
                        st.success("æˆªå›¾å·²ç¼“å­˜ï¼")
                    
                    if info['selected_image']:
                        st.image(info['selected_image'], caption="å½“å‰å·²ç»‘å®šçš„å›¾è¡¨", width=200)
                    else:
                        st.warning("å°šæœªç»‘å®šå›¾è¡¨")

            st.divider()
            if st.button("ğŸ’¾ ä¿å­˜å¹¶æ ‡è®°ä¸º[å·²å®¡æ ¸]", type="primary", key=f"save_{fname}"):
                info['extracted_data'] = {
                    'title': new_title, 'purpose': new_purpose,
                    'conclusion': new_conclusions, 'params': new_params,
                    'formulas': new_formulas, 'comments': new_comments, 'why': new_why
                }
                info['status'] = "å·²å®¡æ ¸"
                st.session_state.word_buffer = None # æ•°æ®å˜æ›´ï¼Œæ¸…é™¤æ—§ç¼“å­˜
                st.toast("ä¿å­˜æˆåŠŸï¼è¯·ç»§ç»­ä¸‹ä¸€ç¯‡æˆ–å»é¢„è§ˆé¡µæŸ¥çœ‹ã€‚")
                st.rerun() # ã€ä¿®å¤ç‚¹ã€‘ä» st.experimental_rerun() æ”¹ä¸º st.rerun()
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©ä¸€ç¯‡è®ºæ–‡è¿›è¡Œç¼–è¾‘ã€‚")

# --- Tab 2: æŠ¥å‘Šé¢„è§ˆ (Word View) ---
with tab_preview:
    st.subheader("ğŸ“„ æœ€ç»ˆæŠ¥å‘Šé¢„è§ˆ (Master Table View)")
    
    reviewed_papers = [p for p in st.session_state.papers_data.values() if p['status'] == "å·²å®¡æ ¸"]
    
    if not reviewed_papers:
        st.warning("âš ï¸ æš‚æ— å·²å®¡æ ¸çš„è®ºæ–‡ã€‚è¯·åœ¨â€œå•ç¯‡ç²¾ä¿®â€é¡µé¢å®Œæˆå®¡æ ¸å¹¶ç‚¹å‡»ä¿å­˜ã€‚")
    else:
        st.write(f"å…± {len(reviewed_papers)} ç¯‡è®ºæ–‡å‡†å¤‡ç”Ÿæˆã€‚")
        
        # 1. å‡†å¤‡é¢„è§ˆæ•°æ® (Pandas DataFrame)
        preview_list = []
        for p in reviewed_papers:
            d = p['extracted_data']
            # æ ¼å¼åŒ–ç»“è®ºä¸ºå­—ç¬¦ä¸²
            cons_str = "\n".join([f"{i+1}. {c}" for i, c in enumerate(d.get('conclusion', []))])
            # æ ¼å¼åŒ–å…¬å¼
            forms_str = "\n".join(d.get('formulas', []))
            
            preview_list.append({
                "Article": d.get('title'),
                "å…·ä½“å†…å®¹(1): ç›®çš„ä¸ç»“è®º": f"ã€ç›®çš„ã€‘\n{d.get('purpose')}\n\nã€ç»“è®ºã€‘\n{cons_str}",
                "å…·ä½“å†…å®¹(2): å‚æ•°/å…¬å¼/å›¾è¡¨": f"ã€å‚æ•°ã€‘\n{d.get('params')}\n\nã€å…¬å¼ã€‘\n{forms_str}\n\nã€å›¾è¡¨ã€‘\n{'âœ… å·²åŒ…å«å›¾ç‰‡' if p['selected_image'] else 'âŒ æ— å›¾ç‰‡'}",
                "Comments": d.get('comments'),
                "Why": d.get('why')
            })
        
        df_preview = pd.DataFrame(preview_list)
        st.table(df_preview) # å±•ç¤ºé™æ€è¡¨æ ¼ï¼Œæ¨¡æ‹Ÿ Word æ•ˆæœ

        st.divider()
        
        # 2. ç”Ÿæˆä¸ä¸‹è½½åŒºåŸŸ
        col_gen, col_down = st.columns([1, 2])
        
        with col_gen:
            # å¼ºåˆ¶é‡æ–°ç”ŸæˆæŒ‰é’®
            if st.button("ğŸ”„ ç”Ÿæˆ/æ›´æ–° Word æ–‡ä»¶"):
                with st.spinner("æ­£åœ¨æ’ç‰ˆ Word æ–‡æ¡£ (åŒ…å«é«˜æ¸…å›¾ç‰‡ä¸å…¬å¼æ¸²æŸ“)..."):
                    gen = WordReportGenerator()
                    for p in reviewed_papers:
                        img_stream = None
                        if p['selected_image']:
                            img_stream = BytesIO()
                            p['selected_image'].save(img_stream, format='PNG')
                            img_stream.seek(0)
                        gen.add_paper_row(p['extracted_data'], img_stream)
                    
                    st.session_state.word_buffer = gen.save_to_bytes()
                st.success("ç”Ÿæˆå®Œæ¯•ï¼")
        
        with col_down:
            if st.session_state.word_buffer:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½æœ€ç»ˆ Word æŠ¥å‘Š (.docx)",
                    data=st.session_state.word_buffer,
                    file_name="SPE_Literature_Review_Master.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                    type="primary"
                )
            else:
                st.caption("ç‚¹å‡»å·¦ä¾§æŒ‰é’®ç”Ÿæˆåå³å¯ä¸‹è½½")